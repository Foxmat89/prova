{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-04-21T10:05:57.962420Z","iopub.execute_input":"2022-04-21T10:05:57.963125Z","iopub.status.idle":"2022-04-21T10:05:57.968341Z","shell.execute_reply.started":"2022-04-21T10:05:57.963093Z","shell.execute_reply":"2022-04-21T10:05:57.967368Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"markdown","source":"## 1. Installation","metadata":{}},{"cell_type":"code","source":"!pip install pyspark","metadata":{"execution":{"iopub.status.busy":"2022-04-21T10:06:06.163079Z","iopub.execute_input":"2022-04-21T10:06:06.163582Z","iopub.status.idle":"2022-04-21T10:06:56.389762Z","shell.execute_reply.started":"2022-04-21T10:06:06.163539Z","shell.execute_reply":"2022-04-21T10:06:56.388725Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stdout","text":"Collecting pyspark\n  Downloading pyspark-3.2.1.tar.gz (281.4 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m281.4/281.4 MB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n\u001b[?25hCollecting py4j==0.10.9.3\n  Downloading py4j-0.10.9.3-py2.py3-none-any.whl (198 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m199.0/199.0 KB\u001b[0m \u001b[31m12.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hBuilding wheels for collected packages: pyspark\n  Building wheel for pyspark (setup.py) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for pyspark: filename=pyspark-3.2.1-py2.py3-none-any.whl size=281853642 sha256=26133dec15059019b3179a93f385674d9733c53b513fe32b78fe4ec39ff00174\n  Stored in directory: /root/.cache/pip/wheels/9f/f5/07/7cd8017084dce4e93e84e92efd1e1d5334db05f2e83bcef74f\nSuccessfully built pyspark\nInstalling collected packages: py4j, pyspark\n  Attempting uninstall: py4j\n    Found existing installation: py4j 0.10.9.5\n    Uninstalling py4j-0.10.9.5:\n      Successfully uninstalled py4j-0.10.9.5\nSuccessfully installed py4j-0.10.9.3 pyspark-3.2.1\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n\u001b[0m","output_type":"stream"}]},{"cell_type":"markdown","source":"## 2. Spark Session","metadata":{}},{"cell_type":"code","source":"from pyspark.sql import SparkSession\n\nspark = SparkSession.builder.getOrCreate()","metadata":{"execution":{"iopub.status.busy":"2022-04-21T10:06:56.392191Z","iopub.execute_input":"2022-04-21T10:06:56.393111Z","iopub.status.idle":"2022-04-21T10:07:01.625976Z","shell.execute_reply.started":"2022-04-21T10:06:56.393072Z","shell.execute_reply":"2022-04-21T10:07:01.623657Z"},"trusted":true},"execution_count":4,"outputs":[{"name":"stderr","text":"WARNING: An illegal reflective access operation has occurred\nWARNING: Illegal reflective access by org.apache.spark.unsafe.Platform (file:/opt/conda/lib/python3.7/site-packages/pyspark/jars/spark-unsafe_2.12-3.2.1.jar) to constructor java.nio.DirectByteBuffer(long,int)\nWARNING: Please consider reporting this to the maintainers of org.apache.spark.unsafe.Platform\nWARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations\nWARNING: All illegal access operations will be denied in a future release\nUsing Spark's default log4j profile: org/apache/spark/log4j-defaults.properties\nSetting default log level to \"WARN\".\nTo adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n22/04/21 10:06:59 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## 3. Dummy data creation","metadata":{}},{"cell_type":"code","source":"sampleData = [\n    {\n        \"employee\": \"James\", \"department\": \"Sales\", \"state\": \"NY\", \"salary\": 90000, \"age\": 34, \"bonus\": 10000\n    },\n    {\n        \"employee\": \"Michael\", \"department\": \"Sales\", \"state\": \"NY\", \"salary\": 86000, \"age\": 56, \"bonus\": 20000\n    },\n    {\n        \"employee\": \"Robert\", \"department\": \"Sales\", \"state\": \"CA\", \"salary\": 81000, \"age\": 39, \"bonus\": 23000\n    },\n    {\n        \"employee\": \"Maria\", \"department\": \"Finance\", \"state\": \"CA\", \"salary\": 90000, \"age\": 24, \"bonus\": 23000\n    },\n    {\n        \"employee\": \"Raman\", \"department\": \"Finance\", \"state\": \"CA\", \"salary\": 99000, \"age\": 40, \"bonus\": 24000\n    },\n    {\n        \"employee\": \"Scott\", \"department\": \"Finance\", \"state\": \"NY\", \"salary\": 83000, \"age\": 36, \"bonus\": 19000\n    },\n    {\n        \"employee\": \"Jen\", \"department\": \"Finance\", \"state\": \"NY\", \"salary\": 79000, \"age\": 53, \"bonus\": 15000\n    },\n    {\n        \"employee\": \"Jeff\", \"department\": \"Marketing\", \"state\": \"CA\", \"salary\": 80000, \"age\": 25, \"bonus\": 18000\n    },\n    {\n        \"employee\": \"Kumar\", \"department\": \"Marketing\", \"state\": \"NY\", \"salary\": 91000, \"age\": 50, \"bonus\": 21000\n    }\n]\n","metadata":{"execution":{"iopub.status.busy":"2022-04-21T10:07:08.814098Z","iopub.execute_input":"2022-04-21T10:07:08.814392Z","iopub.status.idle":"2022-04-21T10:07:08.825167Z","shell.execute_reply.started":"2022-04-21T10:07:08.814361Z","shell.execute_reply":"2022-04-21T10:07:08.824086Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"markdown","source":"## 4. create Spark DataFrame and show","metadata":{}},{"cell_type":"code","source":"# to read from a .csv file\n# df = spark.read.csv(\"<file_path>\")\n\ndf = spark.createDataFrame(sampleData)\ndf.show()","metadata":{"execution":{"iopub.status.busy":"2022-04-21T10:07:13.242168Z","iopub.execute_input":"2022-04-21T10:07:13.242475Z","iopub.status.idle":"2022-04-21T10:07:19.462472Z","shell.execute_reply.started":"2022-04-21T10:07:13.242436Z","shell.execute_reply":"2022-04-21T10:07:19.461641Z"},"trusted":true},"execution_count":6,"outputs":[{"name":"stderr","text":"                                                                                \r","output_type":"stream"},{"name":"stdout","text":"+---+-----+----------+--------+------+-----+\n|age|bonus|department|employee|salary|state|\n+---+-----+----------+--------+------+-----+\n| 34|10000|     Sales|   James| 90000|   NY|\n| 56|20000|     Sales| Michael| 86000|   NY|\n| 39|23000|     Sales|  Robert| 81000|   CA|\n| 24|23000|   Finance|   Maria| 90000|   CA|\n| 40|24000|   Finance|   Raman| 99000|   CA|\n| 36|19000|   Finance|   Scott| 83000|   NY|\n| 53|15000|   Finance|     Jen| 79000|   NY|\n| 25|18000| Marketing|    Jeff| 80000|   CA|\n| 50|21000| Marketing|   Kumar| 91000|   NY|\n+---+-----+----------+--------+------+-----+\n\n","output_type":"stream"}]},{"cell_type":"markdown","source":"### show as a pandas df","metadata":{}},{"cell_type":"code","source":"df.limit(5).toPandas()","metadata":{"execution":{"iopub.status.busy":"2022-04-21T10:07:23.702229Z","iopub.execute_input":"2022-04-21T10:07:23.702517Z","iopub.status.idle":"2022-04-21T10:07:24.057290Z","shell.execute_reply.started":"2022-04-21T10:07:23.702487Z","shell.execute_reply":"2022-04-21T10:07:24.056279Z"},"trusted":true},"execution_count":7,"outputs":[{"execution_count":7,"output_type":"execute_result","data":{"text/plain":"   age  bonus department employee  salary state\n0   34  10000      Sales    James   90000    NY\n1   56  20000      Sales  Michael   86000    NY\n2   39  23000      Sales   Robert   81000    CA\n3   24  23000    Finance    Maria   90000    CA\n4   40  24000    Finance    Raman   99000    CA","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>age</th>\n      <th>bonus</th>\n      <th>department</th>\n      <th>employee</th>\n      <th>salary</th>\n      <th>state</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>34</td>\n      <td>10000</td>\n      <td>Sales</td>\n      <td>James</td>\n      <td>90000</td>\n      <td>NY</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>56</td>\n      <td>20000</td>\n      <td>Sales</td>\n      <td>Michael</td>\n      <td>86000</td>\n      <td>NY</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>39</td>\n      <td>23000</td>\n      <td>Sales</td>\n      <td>Robert</td>\n      <td>81000</td>\n      <td>CA</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>24</td>\n      <td>23000</td>\n      <td>Finance</td>\n      <td>Maria</td>\n      <td>90000</td>\n      <td>CA</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>40</td>\n      <td>24000</td>\n      <td>Finance</td>\n      <td>Raman</td>\n      <td>99000</td>\n      <td>CA</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"markdown","source":"### print schema","metadata":{}},{"cell_type":"code","source":"df.printSchema()","metadata":{"execution":{"iopub.status.busy":"2022-04-21T10:07:26.247145Z","iopub.execute_input":"2022-04-21T10:07:26.247858Z","iopub.status.idle":"2022-04-21T10:07:26.254458Z","shell.execute_reply.started":"2022-04-21T10:07:26.247822Z","shell.execute_reply":"2022-04-21T10:07:26.253862Z"},"trusted":true},"execution_count":8,"outputs":[{"name":"stdout","text":"root\n |-- age: long (nullable = true)\n |-- bonus: long (nullable = true)\n |-- department: string (nullable = true)\n |-- employee: string (nullable = true)\n |-- salary: long (nullable = true)\n |-- state: string (nullable = true)\n\n","output_type":"stream"}]},{"cell_type":"markdown","source":"### rename columns","metadata":{}},{"cell_type":"code","source":"df = df.withColumnRenamed(\"employee\", \"employee_name\")\ndf.printSchema()\n\n## rename for all columns\n# df = df.toDF(*[\"age_xy\", \"bonus_xy\", \"department_xy\", \"employee_xy\", \"salary_xy\", \"state_xy\"])","metadata":{"execution":{"iopub.status.busy":"2022-04-21T10:07:27.527144Z","iopub.execute_input":"2022-04-21T10:07:27.527442Z","iopub.status.idle":"2022-04-21T10:07:27.547726Z","shell.execute_reply.started":"2022-04-21T10:07:27.527407Z","shell.execute_reply":"2022-04-21T10:07:27.546872Z"},"trusted":true},"execution_count":9,"outputs":[{"name":"stdout","text":"root\n |-- age: long (nullable = true)\n |-- bonus: long (nullable = true)\n |-- department: string (nullable = true)\n |-- employee_name: string (nullable = true)\n |-- salary: long (nullable = true)\n |-- state: string (nullable = true)\n\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## select columns","metadata":{}},{"cell_type":"code","source":"df1 = df.select(\"employee_name\", \"age\", \"state\")\ndf1.show()","metadata":{"execution":{"iopub.status.busy":"2022-04-21T10:07:28.812280Z","iopub.execute_input":"2022-04-21T10:07:28.812801Z","iopub.status.idle":"2022-04-21T10:07:29.185171Z","shell.execute_reply.started":"2022-04-21T10:07:28.812752Z","shell.execute_reply":"2022-04-21T10:07:29.184282Z"},"trusted":true},"execution_count":10,"outputs":[{"name":"stdout","text":"+-------------+---+-----+\n|employee_name|age|state|\n+-------------+---+-----+\n|        James| 34|   NY|\n|      Michael| 56|   NY|\n|       Robert| 39|   CA|\n|        Maria| 24|   CA|\n|        Raman| 40|   CA|\n|        Scott| 36|   NY|\n|          Jen| 53|   NY|\n|         Jeff| 25|   CA|\n|        Kumar| 50|   NY|\n+-------------+---+-----+\n\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## sort","metadata":{}},{"cell_type":"code","source":"## by default, in ascending order\ndf.sort('age').show()","metadata":{"execution":{"iopub.status.busy":"2022-04-21T10:07:29.942172Z","iopub.execute_input":"2022-04-21T10:07:29.942869Z","iopub.status.idle":"2022-04-21T10:07:30.398634Z","shell.execute_reply.started":"2022-04-21T10:07:29.942832Z","shell.execute_reply":"2022-04-21T10:07:30.397998Z"},"trusted":true},"execution_count":11,"outputs":[{"name":"stdout","text":"+---+-----+----------+-------------+------+-----+\n|age|bonus|department|employee_name|salary|state|\n+---+-----+----------+-------------+------+-----+\n| 24|23000|   Finance|        Maria| 90000|   CA|\n| 25|18000| Marketing|         Jeff| 80000|   CA|\n| 34|10000|     Sales|        James| 90000|   NY|\n| 36|19000|   Finance|        Scott| 83000|   NY|\n| 39|23000|     Sales|       Robert| 81000|   CA|\n| 40|24000|   Finance|        Raman| 99000|   CA|\n| 50|21000| Marketing|        Kumar| 91000|   NY|\n| 53|15000|   Finance|          Jen| 79000|   NY|\n| 56|20000|     Sales|      Michael| 86000|   NY|\n+---+-----+----------+-------------+------+-----+\n\n","output_type":"stream"}]},{"cell_type":"code","source":"## sort in descending order\nfrom pyspark.sql import functions as F\n\ndf.sort(F.desc('age')).show()","metadata":{"execution":{"iopub.status.busy":"2022-04-21T10:07:30.474020Z","iopub.execute_input":"2022-04-21T10:07:30.474377Z","iopub.status.idle":"2022-04-21T10:07:30.737856Z","shell.execute_reply.started":"2022-04-21T10:07:30.474331Z","shell.execute_reply":"2022-04-21T10:07:30.736982Z"},"trusted":true},"execution_count":12,"outputs":[{"name":"stdout","text":"+---+-----+----------+-------------+------+-----+\n|age|bonus|department|employee_name|salary|state|\n+---+-----+----------+-------------+------+-----+\n| 56|20000|     Sales|      Michael| 86000|   NY|\n| 53|15000|   Finance|          Jen| 79000|   NY|\n| 50|21000| Marketing|        Kumar| 91000|   NY|\n| 40|24000|   Finance|        Raman| 99000|   CA|\n| 39|23000|     Sales|       Robert| 81000|   CA|\n| 36|19000|   Finance|        Scott| 83000|   NY|\n| 34|10000|     Sales|        James| 90000|   NY|\n| 25|18000| Marketing|         Jeff| 80000|   CA|\n| 24|23000|   Finance|        Maria| 90000|   CA|\n+---+-----+----------+-------------+------+-----+\n\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## create a new column using Spark UDF","metadata":{}},{"cell_type":"code","source":"# normal python function\ndef salary_in_k(x):\n    return x/1000\n\n# convert the above function to spark UDF and return type of function (Typecast)\nfrom pyspark.sql import types as T\n\nsalary_in_k_udf = F.udf(salary_in_k, T.DoubleType())\n\n# creatinfg column\ndf = df.withColumn('salary_in_k', salary_in_k_udf(F.col('salary')))\n\ndf.show()\n                   ","metadata":{"execution":{"iopub.status.busy":"2022-04-21T10:07:32.007218Z","iopub.execute_input":"2022-04-21T10:07:32.007516Z","iopub.status.idle":"2022-04-21T10:07:33.209051Z","shell.execute_reply.started":"2022-04-21T10:07:32.007484Z","shell.execute_reply":"2022-04-21T10:07:33.208094Z"},"trusted":true},"execution_count":13,"outputs":[{"name":"stderr","text":"                                                                                \r","output_type":"stream"},{"name":"stdout","text":"+---+-----+----------+-------------+------+-----+-----------+\n|age|bonus|department|employee_name|salary|state|salary_in_k|\n+---+-----+----------+-------------+------+-----+-----------+\n| 34|10000|     Sales|        James| 90000|   NY|       90.0|\n| 56|20000|     Sales|      Michael| 86000|   NY|       86.0|\n| 39|23000|     Sales|       Robert| 81000|   CA|       81.0|\n| 24|23000|   Finance|        Maria| 90000|   CA|       90.0|\n| 40|24000|   Finance|        Raman| 99000|   CA|       99.0|\n| 36|19000|   Finance|        Scott| 83000|   NY|       83.0|\n| 53|15000|   Finance|          Jen| 79000|   NY|       79.0|\n| 25|18000| Marketing|         Jeff| 80000|   CA|       80.0|\n| 50|21000| Marketing|        Kumar| 91000|   NY|       91.0|\n+---+-----+----------+-------------+------+-----+-----------+\n\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## Filter","metadata":{}},{"cell_type":"code","source":"df.filter((df.age >= 50) & (df.salary_in_k >= 80.0)).show()","metadata":{"execution":{"iopub.status.busy":"2022-04-21T10:07:33.241911Z","iopub.execute_input":"2022-04-21T10:07:33.242168Z","iopub.status.idle":"2022-04-21T10:07:33.943287Z","shell.execute_reply.started":"2022-04-21T10:07:33.242136Z","shell.execute_reply":"2022-04-21T10:07:33.942381Z"},"trusted":true},"execution_count":14,"outputs":[{"name":"stdout","text":"+---+-----+----------+-------------+------+-----+-----------+\n|age|bonus|department|employee_name|salary|state|salary_in_k|\n+---+-----+----------+-------------+------+-----+-----------+\n| 56|20000|     Sales|      Michael| 86000|   NY|       86.0|\n| 50|21000| Marketing|        Kumar| 91000|   NY|       91.0|\n+---+-----+----------+-------------+------+-----+-----------+\n\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## groupBy","metadata":{"execution":{"iopub.status.busy":"2022-04-21T09:47:36.577725Z","iopub.execute_input":"2022-04-21T09:47:36.578062Z","iopub.status.idle":"2022-04-21T09:47:36.581688Z","shell.execute_reply.started":"2022-04-21T09:47:36.578028Z","shell.execute_reply":"2022-04-21T09:47:36.581003Z"}}},{"cell_type":"code","source":"# groupBy on single column with sum agg\ndf.groupBy('department').sum('salary').show()","metadata":{"execution":{"iopub.status.busy":"2022-04-21T10:07:34.662242Z","iopub.execute_input":"2022-04-21T10:07:34.663205Z","iopub.status.idle":"2022-04-21T10:07:35.659926Z","shell.execute_reply.started":"2022-04-21T10:07:34.663149Z","shell.execute_reply":"2022-04-21T10:07:35.659063Z"},"trusted":true},"execution_count":15,"outputs":[{"name":"stdout","text":"+----------+-----------+\n|department|sum(salary)|\n+----------+-----------+\n|     Sales|     257000|\n|   Finance|     351000|\n| Marketing|     171000|\n+----------+-----------+\n\n","output_type":"stream"}]},{"cell_type":"code","source":"# groupBy on multiple columns\ndf.groupBy('department', 'state').sum('salary', 'bonus').show()","metadata":{"execution":{"iopub.status.busy":"2022-04-21T10:07:35.661443Z","iopub.execute_input":"2022-04-21T10:07:35.661775Z","iopub.status.idle":"2022-04-21T10:07:36.199868Z","shell.execute_reply.started":"2022-04-21T10:07:35.661733Z","shell.execute_reply":"2022-04-21T10:07:36.199018Z"},"trusted":true},"execution_count":16,"outputs":[{"name":"stdout","text":"+----------+-----+-----------+----------+\n|department|state|sum(salary)|sum(bonus)|\n+----------+-----+-----------+----------+\n|     Sales|   NY|     176000|     30000|\n|     Sales|   CA|      81000|     23000|\n|   Finance|   CA|     189000|     47000|\n|   Finance|   NY|     162000|     34000|\n| Marketing|   NY|      91000|     21000|\n| Marketing|   CA|      80000|     18000|\n+----------+-----+-----------+----------+\n\n","output_type":"stream"}]},{"cell_type":"code","source":"# running more aggregations at a time\ndf.groupBy('department').agg(F.sum('salary'), F.avg('salary'),\n                            F.min('bonus'), F.max('bonus')).show()","metadata":{"execution":{"iopub.status.busy":"2022-04-21T10:07:36.201380Z","iopub.execute_input":"2022-04-21T10:07:36.201664Z","iopub.status.idle":"2022-04-21T10:07:36.668153Z","shell.execute_reply.started":"2022-04-21T10:07:36.201623Z","shell.execute_reply":"2022-04-21T10:07:36.666932Z"},"trusted":true},"execution_count":17,"outputs":[{"name":"stdout","text":"+----------+-----------+-----------------+----------+----------+\n|department|sum(salary)|      avg(salary)|min(bonus)|max(bonus)|\n+----------+-----------+-----------------+----------+----------+\n|     Sales|     257000|85666.66666666667|     10000|     23000|\n|   Finance|     351000|          87750.0|     15000|     24000|\n| Marketing|     171000|          85500.0|     18000|     21000|\n+----------+-----------+-----------------+----------+----------+\n\n","output_type":"stream"}]},{"cell_type":"code","source":"# using filter and alias on the aggreated data\ndf.groupBy('department').agg(F.sum('salary').alias('sum_salary'), \n                             F.avg('salary').alias('avg_salary'),\n                             F.min('bonus').alias('min_bonus'), \n                             F.max('bonus').alias('max_bonus')).where(\n                                                                F.col('min_bonus') >= 15000).show()","metadata":{"execution":{"iopub.status.busy":"2022-04-21T10:07:43.868239Z","iopub.execute_input":"2022-04-21T10:07:43.868578Z","iopub.status.idle":"2022-04-21T10:07:44.300390Z","shell.execute_reply.started":"2022-04-21T10:07:43.868544Z","shell.execute_reply":"2022-04-21T10:07:44.299160Z"},"trusted":true},"execution_count":18,"outputs":[{"name":"stdout","text":"+----------+----------+----------+---------+---------+\n|department|sum_salary|avg_salary|min_bonus|max_bonus|\n+----------+----------+----------+---------+---------+\n|   Finance|    351000|   87750.0|    15000|    24000|\n| Marketing|    171000|   85500.0|    18000|    21000|\n+----------+----------+----------+---------+---------+\n\n","output_type":"stream"}]},{"cell_type":"code","source":"## collect aggregated list\ndf.groupBy('department').agg(F.collect_list('state')).alias('state_list').show()","metadata":{"execution":{"iopub.status.busy":"2022-04-21T10:07:44.397463Z","iopub.execute_input":"2022-04-21T10:07:44.398058Z","iopub.status.idle":"2022-04-21T10:07:44.755475Z","shell.execute_reply.started":"2022-04-21T10:07:44.398020Z","shell.execute_reply":"2022-04-21T10:07:44.754614Z"},"trusted":true},"execution_count":19,"outputs":[{"name":"stdout","text":"+----------+-------------------+\n|department|collect_list(state)|\n+----------+-------------------+\n|     Sales|       [NY, NY, CA]|\n|   Finance|   [CA, CA, NY, NY]|\n| Marketing|           [CA, NY]|\n+----------+-------------------+\n\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## Joins","metadata":{}},{"cell_type":"code","source":"df1 = df.select(\"employee_name\", \"age\", \"state\", \"salary_in_k\")\ndf2 = df.select(\"salary\", \"department\", \"bonus\", \"employee_name\", \"age\")\ndf1.show(), df2.show()","metadata":{"execution":{"iopub.status.busy":"2022-04-21T10:07:57.042657Z","iopub.execute_input":"2022-04-21T10:07:57.042956Z","iopub.status.idle":"2022-04-21T10:07:57.563718Z","shell.execute_reply.started":"2022-04-21T10:07:57.042924Z","shell.execute_reply":"2022-04-21T10:07:57.562962Z"},"trusted":true},"execution_count":20,"outputs":[{"name":"stdout","text":"+-------------+---+-----+-----------+\n|employee_name|age|state|salary_in_k|\n+-------------+---+-----+-----------+\n|        James| 34|   NY|       90.0|\n|      Michael| 56|   NY|       86.0|\n|       Robert| 39|   CA|       81.0|\n|        Maria| 24|   CA|       90.0|\n|        Raman| 40|   CA|       99.0|\n|        Scott| 36|   NY|       83.0|\n|          Jen| 53|   NY|       79.0|\n|         Jeff| 25|   CA|       80.0|\n|        Kumar| 50|   NY|       91.0|\n+-------------+---+-----+-----------+\n\n+------+----------+-----+-------------+---+\n|salary|department|bonus|employee_name|age|\n+------+----------+-----+-------------+---+\n| 90000|     Sales|10000|        James| 34|\n| 86000|     Sales|20000|      Michael| 56|\n| 81000|     Sales|23000|       Robert| 39|\n| 90000|   Finance|23000|        Maria| 24|\n| 99000|   Finance|24000|        Raman| 40|\n| 83000|   Finance|19000|        Scott| 36|\n| 79000|   Finance|15000|          Jen| 53|\n| 80000| Marketing|18000|         Jeff| 25|\n| 91000| Marketing|21000|        Kumar| 50|\n+------+----------+-----+-------------+---+\n\n","output_type":"stream"},{"execution_count":20,"output_type":"execute_result","data":{"text/plain":"(None, None)"},"metadata":{}}]},{"cell_type":"code","source":"df = df1.join(df2, [\"employee_name\", \"age\"], how='inner') # how='left'/'right'\ndf.show()","metadata":{"execution":{"iopub.status.busy":"2022-04-21T10:08:02.742343Z","iopub.execute_input":"2022-04-21T10:08:02.742591Z","iopub.status.idle":"2022-04-21T10:08:03.515132Z","shell.execute_reply.started":"2022-04-21T10:08:02.742566Z","shell.execute_reply":"2022-04-21T10:08:03.514270Z"},"trusted":true},"execution_count":21,"outputs":[{"name":"stdout","text":"+-------------+---+-----+-----------+------+----------+-----+\n|employee_name|age|state|salary_in_k|salary|department|bonus|\n+-------------+---+-----+-----------+------+----------+-----+\n|        James| 34|   NY|       90.0| 90000|     Sales|10000|\n|         Jeff| 25|   CA|       80.0| 80000| Marketing|18000|\n|          Jen| 53|   NY|       79.0| 79000|   Finance|15000|\n|        Kumar| 50|   NY|       91.0| 91000| Marketing|21000|\n|        Maria| 24|   CA|       90.0| 90000|   Finance|23000|\n|      Michael| 56|   NY|       86.0| 86000|     Sales|20000|\n|        Raman| 40|   CA|       99.0| 99000|   Finance|24000|\n|       Robert| 39|   CA|       81.0| 81000|     Sales|23000|\n|        Scott| 36|   NY|       83.0| 83000|   Finance|19000|\n+-------------+---+-----+-----------+------+----------+-----+\n\n","output_type":"stream"}]},{"cell_type":"code","source":"# when one table is too big and other is too small -> try broadcasting/map side joins\ndf = df1.join(F.broadcast(df2), [\"employee_name\", \"age\"], how='inner')\ndf.show()","metadata":{"execution":{"iopub.status.busy":"2022-04-21T10:10:40.093280Z","iopub.execute_input":"2022-04-21T10:10:40.094248Z","iopub.status.idle":"2022-04-21T10:10:40.586731Z","shell.execute_reply.started":"2022-04-21T10:10:40.094190Z","shell.execute_reply":"2022-04-21T10:10:40.585822Z"},"trusted":true},"execution_count":22,"outputs":[{"name":"stdout","text":"+-------------+---+-----+-----------+------+----------+-----+\n|employee_name|age|state|salary_in_k|salary|department|bonus|\n+-------------+---+-----+-----------+------+----------+-----+\n|        James| 34|   NY|       90.0| 90000|     Sales|10000|\n|      Michael| 56|   NY|       86.0| 86000|     Sales|20000|\n|       Robert| 39|   CA|       81.0| 81000|     Sales|23000|\n|        Maria| 24|   CA|       90.0| 90000|   Finance|23000|\n|        Raman| 40|   CA|       99.0| 99000|   Finance|24000|\n|        Scott| 36|   NY|       83.0| 83000|   Finance|19000|\n|          Jen| 53|   NY|       79.0| 79000|   Finance|15000|\n|         Jeff| 25|   CA|       80.0| 80000| Marketing|18000|\n|        Kumar| 50|   NY|       91.0| 91000| Marketing|21000|\n+-------------+---+-----+-----------+------+----------+-----+\n\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## Use SQL with DataFrame","metadata":{}},{"cell_type":"code","source":"# register the df to a table\ndf.registerTempTable('df_table')\n\nfrom pyspark.sql import SQLContext\nsqlContext = SQLContext(spark)\n\nsqlContext.sql('select * from df_table where age >= 50').show()\n","metadata":{"execution":{"iopub.status.busy":"2022-04-21T10:17:56.656627Z","iopub.execute_input":"2022-04-21T10:17:56.657654Z","iopub.status.idle":"2022-04-21T10:17:57.253755Z","shell.execute_reply.started":"2022-04-21T10:17:56.657602Z","shell.execute_reply":"2022-04-21T10:17:57.252872Z"},"trusted":true},"execution_count":26,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.7/site-packages/pyspark/sql/context.py:79: FutureWarning: Deprecated in 3.0.0. Use SparkSession.builder.getOrCreate() instead.\n  FutureWarning\n","output_type":"stream"},{"name":"stdout","text":"+-------------+---+-----+-----------+------+----------+-----+\n|employee_name|age|state|salary_in_k|salary|department|bonus|\n+-------------+---+-----+-----------+------+----------+-----+\n|      Michael| 56|   NY|       86.0| 86000|     Sales|20000|\n|          Jen| 53|   NY|       79.0| 79000|   Finance|15000|\n|        Kumar| 50|   NY|       91.0| 91000| Marketing|21000|\n+-------------+---+-----+-----------+------+----------+-----+\n\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## Using RDD","metadata":{}},{"cell_type":"code","source":"import math\nfrom pyspark.sql import Row\n\ndef row_function(row):\n    # convert row to python dict()\n    row_dict = row.asDict()\n    \n    # add a new key and value\n    row_dict['exp_bonus'] = float(np.log(row_dict['bonus']))\n    \n    # convert dict back to row \n    newRow = Row(**row_dict)\n    \n    return newRow\n\n# convert df to RDD\ndf_rdd = df.rdd\n\n# apply above function to RDD\ndf_rdd_new = df_rdd.map(lambda row: row_function(row))\n\n# convert rdd back to DataFrame\ndf_new = spark.createDataFrame(df_rdd_new)\n\ndf_new.show()","metadata":{"execution":{"iopub.status.busy":"2022-04-21T10:28:32.703683Z","iopub.execute_input":"2022-04-21T10:28:32.704089Z","iopub.status.idle":"2022-04-21T10:28:33.005388Z","shell.execute_reply.started":"2022-04-21T10:28:32.704055Z","shell.execute_reply":"2022-04-21T10:28:33.004458Z"},"trusted":true},"execution_count":28,"outputs":[{"name":"stdout","text":"+-------------+---+-----+-----------+------+----------+-----+------------------+\n|employee_name|age|state|salary_in_k|salary|department|bonus|         exp_bonus|\n+-------------+---+-----+-----------+------+----------+-----+------------------+\n|        James| 34|   NY|       90.0| 90000|     Sales|10000| 9.210340371976184|\n|      Michael| 56|   NY|       86.0| 86000|     Sales|20000| 9.903487552536127|\n|       Robert| 39|   CA|       81.0| 81000|     Sales|23000|10.043249494911286|\n|        Maria| 24|   CA|       90.0| 90000|   Finance|23000|10.043249494911286|\n|        Raman| 40|   CA|       99.0| 99000|   Finance|24000|10.085809109330082|\n|        Scott| 36|   NY|       83.0| 83000|   Finance|19000| 9.852194258148577|\n|          Jen| 53|   NY|       79.0| 79000|   Finance|15000| 9.615805480084347|\n|         Jeff| 25|   CA|       80.0| 80000| Marketing|18000| 9.798127036878302|\n|        Kumar| 50|   NY|       91.0| 91000| Marketing|21000|  9.95227771670556|\n+-------------+---+-----+-----------+------+----------+-----+------------------+\n\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## Using Pandas UDF","metadata":{}},{"cell_type":"code","source":"df.printSchema()","metadata":{"execution":{"iopub.status.busy":"2022-04-21T10:30:23.755229Z","iopub.execute_input":"2022-04-21T10:30:23.755572Z","iopub.status.idle":"2022-04-21T10:30:23.761419Z","shell.execute_reply.started":"2022-04-21T10:30:23.755534Z","shell.execute_reply":"2022-04-21T10:30:23.760602Z"},"trusted":true},"execution_count":29,"outputs":[{"name":"stdout","text":"root\n |-- employee_name: string (nullable = true)\n |-- age: long (nullable = true)\n |-- state: string (nullable = true)\n |-- salary_in_k: double (nullable = true)\n |-- salary: long (nullable = true)\n |-- department: string (nullable = true)\n |-- bonus: long (nullable = true)\n\n","output_type":"stream"}]},{"cell_type":"code","source":"## get normalized bonus grouped by department\n\n# Declare the schema for the output of our function\noutSchema = T.StructType([T.StructField('employee_name', T.StringType(),True),\n                        T.StructField('age', T.LongType(),True),\n                        T.StructField('state', T.StringType(),True),\n                        T.StructField('salary', T.LongType(),True),\n                        T.StructField('salary_in_k', T.DoubleType(),True),\n                        T.StructField('department', T.StringType(),True),\n                        T.StructField('bonus', T.LongType(),True),\n                        T.StructField('normalized_bonus', T.DoubleType(),True)\n                       ])\n\n# decorate our function with pandas_udf decorator\n@F.pandas_udf(outSchema, F.PandasUDFType.GROUPED_MAP)\ndef subtract_mean(pdf):\n    # pdf is a pandas.DataFrame\n    v = pdf.bonus\n    v = v - v.mean()\n    pdf['normalized_bonus'] = v\n    \n    return pdf\n\nconfirmed_groupwise_normalization = df.groupby(\"department\").apply(subtract_mean)\n\nconfirmed_groupwise_normalization.toPandas()","metadata":{"execution":{"iopub.status.busy":"2022-04-21T10:37:03.003638Z","iopub.execute_input":"2022-04-21T10:37:03.003938Z","iopub.status.idle":"2022-04-21T10:37:03.953380Z","shell.execute_reply.started":"2022-04-21T10:37:03.003899Z","shell.execute_reply":"2022-04-21T10:37:03.952313Z"},"trusted":true},"execution_count":33,"outputs":[{"name":"stderr","text":"                                                                                \r","output_type":"stream"},{"execution_count":33,"output_type":"execute_result","data":{"text/plain":"  employee_name  age state  salary  salary_in_k department  bonus  \\\n0         Maria   24    CA   90000         90.0    Finance  23000   \n1         Raman   40    CA   99000         99.0    Finance  24000   \n2         Scott   36    NY   83000         83.0    Finance  19000   \n3           Jen   53    NY   79000         79.0    Finance  15000   \n4          Jeff   25    CA   80000         80.0  Marketing  18000   \n5         Kumar   50    NY   91000         91.0  Marketing  21000   \n6         James   34    NY   90000         90.0      Sales  10000   \n7       Michael   56    NY   86000         86.0      Sales  20000   \n8        Robert   39    CA   81000         81.0      Sales  23000   \n\n   normalized_bonus  \n0       2750.000000  \n1       3750.000000  \n2      -1250.000000  \n3      -5250.000000  \n4      -1500.000000  \n5       1500.000000  \n6      -7666.666667  \n7       2333.333333  \n8       5333.333333  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>employee_name</th>\n      <th>age</th>\n      <th>state</th>\n      <th>salary</th>\n      <th>salary_in_k</th>\n      <th>department</th>\n      <th>bonus</th>\n      <th>normalized_bonus</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Maria</td>\n      <td>24</td>\n      <td>CA</td>\n      <td>90000</td>\n      <td>90.0</td>\n      <td>Finance</td>\n      <td>23000</td>\n      <td>2750.000000</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Raman</td>\n      <td>40</td>\n      <td>CA</td>\n      <td>99000</td>\n      <td>99.0</td>\n      <td>Finance</td>\n      <td>24000</td>\n      <td>3750.000000</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Scott</td>\n      <td>36</td>\n      <td>NY</td>\n      <td>83000</td>\n      <td>83.0</td>\n      <td>Finance</td>\n      <td>19000</td>\n      <td>-1250.000000</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Jen</td>\n      <td>53</td>\n      <td>NY</td>\n      <td>79000</td>\n      <td>79.0</td>\n      <td>Finance</td>\n      <td>15000</td>\n      <td>-5250.000000</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Jeff</td>\n      <td>25</td>\n      <td>CA</td>\n      <td>80000</td>\n      <td>80.0</td>\n      <td>Marketing</td>\n      <td>18000</td>\n      <td>-1500.000000</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>Kumar</td>\n      <td>50</td>\n      <td>NY</td>\n      <td>91000</td>\n      <td>91.0</td>\n      <td>Marketing</td>\n      <td>21000</td>\n      <td>1500.000000</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>James</td>\n      <td>34</td>\n      <td>NY</td>\n      <td>90000</td>\n      <td>90.0</td>\n      <td>Sales</td>\n      <td>10000</td>\n      <td>-7666.666667</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>Michael</td>\n      <td>56</td>\n      <td>NY</td>\n      <td>86000</td>\n      <td>86.0</td>\n      <td>Sales</td>\n      <td>20000</td>\n      <td>2333.333333</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>Robert</td>\n      <td>39</td>\n      <td>CA</td>\n      <td>81000</td>\n      <td>81.0</td>\n      <td>Sales</td>\n      <td>23000</td>\n      <td>5333.333333</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"markdown","source":"## Mllib","metadata":{}},{"cell_type":"code","source":"from pyspark.ml import Pipeline\nfrom pyspark.ml.feature import VectorAssembler, StringIndexer\n\n# category encoding\nindexers = [StringIndexer(inputCol=column, outputCol=column+'_idx'\n                         ) for column in [\"department\", \"employee_name\", \"state\"]]\n\n# create pieline for indexers\npipeline = Pipeline(stages=indexers)\n\n# fit indexer pipeline on df and transform\nindexed = pipeline.fit(df).transform(df)\nindexed.show()","metadata":{"execution":{"iopub.status.busy":"2022-04-21T10:45:19.533848Z","iopub.execute_input":"2022-04-21T10:45:19.534445Z","iopub.status.idle":"2022-04-21T10:45:22.877799Z","shell.execute_reply.started":"2022-04-21T10:45:19.534403Z","shell.execute_reply":"2022-04-21T10:45:22.876868Z"},"trusted":true},"execution_count":34,"outputs":[{"name":"stdout","text":"+-------------+---+-----+-----------+------+----------+-----+--------------+-----------------+---------+\n|employee_name|age|state|salary_in_k|salary|department|bonus|department_idx|employee_name_idx|state_idx|\n+-------------+---+-----+-----------+------+----------+-----+--------------+-----------------+---------+\n|        James| 34|   NY|       90.0| 90000|     Sales|10000|           1.0|              0.0|      0.0|\n|      Michael| 56|   NY|       86.0| 86000|     Sales|20000|           1.0|              5.0|      0.0|\n|       Robert| 39|   CA|       81.0| 81000|     Sales|23000|           1.0|              7.0|      1.0|\n|        Maria| 24|   CA|       90.0| 90000|   Finance|23000|           0.0|              4.0|      1.0|\n|        Raman| 40|   CA|       99.0| 99000|   Finance|24000|           0.0|              6.0|      1.0|\n|        Scott| 36|   NY|       83.0| 83000|   Finance|19000|           0.0|              8.0|      0.0|\n|          Jen| 53|   NY|       79.0| 79000|   Finance|15000|           0.0|              2.0|      0.0|\n|         Jeff| 25|   CA|       80.0| 80000| Marketing|18000|           2.0|              1.0|      1.0|\n|        Kumar| 50|   NY|       91.0| 91000| Marketing|21000|           2.0|              3.0|      0.0|\n+-------------+---+-----+-----------+------+----------+-----+--------------+-----------------+---------+\n\n","output_type":"stream"}]},{"cell_type":"code","source":"## correlation matrix\nfrom pyspark.ml.stat import Correlation\n\n# convert to vector column first\nvector_col = 'corr_features'\ncorr_cols = list(set(indexed.columns) - set([\"department\", \"employee_name\", \"state\"]))\n\n# vector assembler\nassembler = VectorAssembler(inputCols=corr_cols, outputCol=vector_col)\nindexed_vector = assembler.transform(indexed).select(vector_col)\n\n# get correlation matrix\nmatrix = Correlation.corr(indexed_vector, vector_col)\n\nresult = matrix.collect()[0]['pearson({})'.format(vector_col)].values\nresult","metadata":{"execution":{"iopub.status.busy":"2022-04-21T10:50:48.301604Z","iopub.execute_input":"2022-04-21T10:50:48.301932Z","iopub.status.idle":"2022-04-21T10:50:50.376707Z","shell.execute_reply.started":"2022-04-21T10:50:48.301895Z","shell.execute_reply":"2022-04-21T10:50:50.375868Z"},"trusted":true},"execution_count":36,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.7/site-packages/pyspark/sql/context.py:127: FutureWarning: Deprecated in 3.0.0. Use SparkSession.builder.getOrCreate() instead.\n  FutureWarning\n","output_type":"stream"},{"execution_count":36,"output_type":"execute_result","data":{"text/plain":"array([ 1.        ,  1.        ,  0.29052843,  0.1369899 ,  0.06978632,\n       -0.15799063, -0.03379182,  1.        ,  1.        ,  0.29052843,\n        0.1369899 ,  0.06978632, -0.15799063, -0.03379182,  0.29052843,\n        0.29052843,  1.        ,  0.59007577,  0.69498803, -0.11942294,\n       -0.03488578,  0.1369899 ,  0.1369899 ,  0.59007577,  1.        ,\n        0.17320508, -0.03162278, -0.63245553,  0.06978632,  0.06978632,\n        0.69498803,  0.17320508,  1.        , -0.43817805,  0.11907012,\n       -0.15799063, -0.15799063, -0.11942294, -0.03162278, -0.43817805,\n        1.        ,  0.0173913 , -0.03379182, -0.03379182, -0.03488578,\n       -0.63245553,  0.11907012,  0.0173913 ,  1.        ])"},"metadata":{}}]},{"cell_type":"code","source":"# corr matrix as a DataFrame\npd.DataFrame(result.reshape(-1, len(corr_cols)), columns=corr_cols, index=corr_cols)","metadata":{"execution":{"iopub.status.busy":"2022-04-21T10:51:54.992838Z","iopub.execute_input":"2022-04-21T10:51:54.993117Z","iopub.status.idle":"2022-04-21T10:51:55.009314Z","shell.execute_reply.started":"2022-04-21T10:51:54.993090Z","shell.execute_reply":"2022-04-21T10:51:55.008483Z"},"trusted":true},"execution_count":37,"outputs":[{"execution_count":37,"output_type":"execute_result","data":{"text/plain":"                   salary_in_k    salary     bonus  state_idx  \\\nsalary_in_k           1.000000  1.000000  0.290528   0.136990   \nsalary                1.000000  1.000000  0.290528   0.136990   \nbonus                 0.290528  0.290528  1.000000   0.590076   \nstate_idx             0.136990  0.136990  0.590076   1.000000   \nemployee_name_idx     0.069786  0.069786  0.694988   0.173205   \ndepartment_idx       -0.157991 -0.157991 -0.119423  -0.031623   \nage                  -0.033792 -0.033792 -0.034886  -0.632456   \n\n                   employee_name_idx  department_idx       age  \nsalary_in_k                 0.069786       -0.157991 -0.033792  \nsalary                      0.069786       -0.157991 -0.033792  \nbonus                       0.694988       -0.119423 -0.034886  \nstate_idx                   0.173205       -0.031623 -0.632456  \nemployee_name_idx           1.000000       -0.438178  0.119070  \ndepartment_idx             -0.438178        1.000000  0.017391  \nage                         0.119070        0.017391  1.000000  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>salary_in_k</th>\n      <th>salary</th>\n      <th>bonus</th>\n      <th>state_idx</th>\n      <th>employee_name_idx</th>\n      <th>department_idx</th>\n      <th>age</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>salary_in_k</th>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>0.290528</td>\n      <td>0.136990</td>\n      <td>0.069786</td>\n      <td>-0.157991</td>\n      <td>-0.033792</td>\n    </tr>\n    <tr>\n      <th>salary</th>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>0.290528</td>\n      <td>0.136990</td>\n      <td>0.069786</td>\n      <td>-0.157991</td>\n      <td>-0.033792</td>\n    </tr>\n    <tr>\n      <th>bonus</th>\n      <td>0.290528</td>\n      <td>0.290528</td>\n      <td>1.000000</td>\n      <td>0.590076</td>\n      <td>0.694988</td>\n      <td>-0.119423</td>\n      <td>-0.034886</td>\n    </tr>\n    <tr>\n      <th>state_idx</th>\n      <td>0.136990</td>\n      <td>0.136990</td>\n      <td>0.590076</td>\n      <td>1.000000</td>\n      <td>0.173205</td>\n      <td>-0.031623</td>\n      <td>-0.632456</td>\n    </tr>\n    <tr>\n      <th>employee_name_idx</th>\n      <td>0.069786</td>\n      <td>0.069786</td>\n      <td>0.694988</td>\n      <td>0.173205</td>\n      <td>1.000000</td>\n      <td>-0.438178</td>\n      <td>0.119070</td>\n    </tr>\n    <tr>\n      <th>department_idx</th>\n      <td>-0.157991</td>\n      <td>-0.157991</td>\n      <td>-0.119423</td>\n      <td>-0.031623</td>\n      <td>-0.438178</td>\n      <td>1.000000</td>\n      <td>0.017391</td>\n    </tr>\n    <tr>\n      <th>age</th>\n      <td>-0.033792</td>\n      <td>-0.033792</td>\n      <td>-0.034886</td>\n      <td>-0.632456</td>\n      <td>0.119070</td>\n      <td>0.017391</td>\n      <td>1.000000</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}